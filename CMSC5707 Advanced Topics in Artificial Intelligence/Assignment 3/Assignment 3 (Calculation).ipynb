{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a224e4f2-54ea-41a7-a5f4-9483e657a767",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb43d92-5588-4de2-b716-36d1f81e98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_entropy_y(labels):\n",
    "    cnt, ttl = defaultdict(lambda: 0), len(labels)\n",
    "    for label in labels:\n",
    "        cnt[label] += 1\n",
    "    \n",
    "    probs = [count / ttl for count in cnt.values()]\n",
    "    \n",
    "    return -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "\n",
    "\n",
    "def get_entropy_x(subsets):\n",
    "    ttl = sum(len(subset) for subset in subsets)\n",
    "    entropies = [get_entropy_y(subset) * len(subset) / ttl for subset in subsets]\n",
    "    \n",
    "    return sum(entropies)\n",
    "\n",
    "\n",
    "X = {\n",
    "    \"Humidity\":[\"Dry\",\"Dry\",\"Medium\",\"Medium\",\"Medium\",\"Medium\",\"Wet\",\"Wet\",\"Wet\"],\n",
    "    \"Temperature\": [\"Cold\",\"Cold\",\"Average\",\"Average\",\"Hot\",\"Hot\",\"Cold\",\"Average\",\"Hot\"],\n",
    "    \"Wind\":[\"High\",\"Low\",\"High\",\"Low\",\"High\",\"Low\",\"Low\",\"Low\",\"High\"],\n",
    "}\n",
    "Y = [\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"]\n",
    "\n",
    "entropy_y = get_entropy_y(Y)\n",
    "\n",
    "info_gains = {}\n",
    "for feature, values in X.items():\n",
    "    subsets = defaultdict(list)\n",
    "    for value, label in zip(values, Y):\n",
    "        subsets[value].append(label)\n",
    "    entropy_x = get_entropy_x(list(subsets.values()))\n",
    "    info_gains[feature] = entropy_y - entropy_x\n",
    "\n",
    "sum(info_gains.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a412cb9-978d-43eb-9be3-086249319244",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d6c5e-5608-40f3-9184-8399218f46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def lemmatise_corpus(corpu):\n",
    "    words = word_tokenize(corpu.lower())\n",
    "    \n",
    "    return \" \".join(lemmatiser.lemmatize(word) for word in words)\n",
    "\n",
    "\n",
    "corpora = [\n",
    "    \"Upon the road I met seven wives\",\n",
    "    \"Every wife had seven sacks\",\n",
    "    \"Every sack had seven cats\",\n",
    "    \"Every cat had seven kits\",\n",
    "]\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "lemmatised_corpora = [lemmatise_corpus(corpus) for corpus in corpora]\n",
    "\n",
    "vectoriser = CountVectorizer(token_pattern=r\"\\b\\w+\\b\")\n",
    "bow = vectoriser.fit_transform(lemmatised_corpora)\n",
    "\n",
    "X = cosine_similarity(bow)\n",
    "indices = np.triu_indices(len(X), k=1)\n",
    "X[indices].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc66b90-d2c7-493e-b5be-0f1ec30c1b75",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e96ddd-0cea-436c-b1aa-c1229e417ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def lemmatise_corpus(corpu):\n",
    "    words = word_tokenize(corpu.lower())\n",
    "    \n",
    "    return \" \".join(lemmatiser.lemmatize(word) for word in words)\n",
    "\n",
    "\n",
    "corpora = [\n",
    "    \"Upon the road I met seven wives\",\n",
    "    \"Every wife had seven sacks\",\n",
    "    \"Every sack had seven cats\",\n",
    "    \"Every cat had seven kits\",\n",
    "]\n",
    "\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "lemmatised_corpora = [lemmatise_corpus(corpus) for corpus in corpora]\n",
    "\n",
    "vectoriser = CountVectorizer(token_pattern=r\"\\b\\w+\\b\")\n",
    "bow = vectoriser.fit_transform(lemmatised_corpora)\n",
    "bow = pd.DataFrame(bow.toarray(), columns=vectoriser.get_feature_names_out())\n",
    "\n",
    "tf = bow.div(bow.sum(axis=1), axis=0)\n",
    "idf = np.log10(len(corpora) / (bow > 0).sum())\n",
    "tfidf = tf * idf\n",
    "\n",
    "X = cosine_similarity(tfidf)\n",
    "X[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47227a9-5ac2-45ba-bec3-620fac8efe19",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161fa7a-a46f-4712-95ff-e10cb269dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "W_x = np.array([\n",
    "    [0.08,0.64,0.77,0.38],\n",
    "    [0.1,0.57,0.29,0.48],\n",
    "    [0.23,0.19,0.15,0.29],\n",
    "])\n",
    "W_h = np.array([\n",
    "    [0.21,0.22,0.23],\n",
    "    [0.31,0.44,0.26],\n",
    "    [0.41,0.54,0.36],\n",
    "])\n",
    "B = np.array([0.41,0.12,0.63])\n",
    "H_1 = np.array([0.3,0.2,0.1])\n",
    "X_1 = np.array([1,0,0,0])\n",
    "\n",
    "np.tanh(np.dot(W_x, X_1) + np.dot(W_h, H_1) + B)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fac8a-8ae5-4d17-8ca8-9052268fbc23",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c8bca-3c62-46cb-8da2-94dbad52da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \n",
    "    return np.exp(z) / sum(np.exp(z))\n",
    "\n",
    "\n",
    "W_y = np.array([\n",
    "    [0.24,0.27,0.35],\n",
    "    [0.15,0.18,0.21],\n",
    "    [0.25,0.26,0.64],\n",
    "    [0.86,0.13,0.41],\n",
    "])\n",
    "H = np.array([0.45,0.56,0.84])\n",
    "\n",
    "softmax(np.dot(W_y, H))[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfecd9-6456-49a0-9134-308fff4eb843",
   "metadata": {},
   "source": [
    "#### Question 15\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a92832-3560-440f-893a-297d7b3bac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "corpora = [\n",
    "    \"The sun has long been set.\",\n",
    "    \"The stars are out by twos and threes.\",\n",
    "    \"The little birds are piping yet.\",\n",
    "    \"Among the bushes and trees.\",\n",
    "]\n",
    "\n",
    "vectoriser = TfidfVectorizer()\n",
    "tfidf = vectoriser.fit_transform(corpora)\n",
    "\n",
    "X = cosine_similarity(tfidf)\n",
    "X[1,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc64dc-aad5-44cb-a015-4fee055bb476",
   "metadata": {},
   "source": [
    "#### Question 16\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882da65-aa86-45e6-a798-e62626c2389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    " \n",
    "rocket = model[\"rocket\"]\n",
    "plane = model[\"plane\"]\n",
    "ship = model[\"ship\"]\n",
    "banana = model[\"banana\"]\n",
    "\n",
    "A = cosine_similarity([rocket], [plane])[0][0]\n",
    "B = cosine_similarity([ship], [banana])[0][0]\n",
    "\n",
    "A - B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
